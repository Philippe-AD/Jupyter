{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bot-0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXB1nfe4ogQgU/QsFNMIGN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Philippe-AD/Jupyter/blob/master/Bot_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZM_Dobd-zcJ",
        "outputId": "a0a0892f-b754-49f1-f4e9-3bb07d3b546b"
      },
      "source": [
        "sentences = [\n",
        "'Alexa, ask Roomba to start vacuuming',\n",
        "'Alexa, ask Braava to start mopping',\n",
        "'Alexa, tell Roomba to stop vacuuming',\n",
        "'Alexa, tell Braava to stop sweeping'   \n",
        "]\n",
        "\n",
        "input =\"Alexa, ask Roomba to start vacuuming\"\n",
        "if input == \"Alexa, ask Roomba to start vacuuming\":\n",
        "  numero = 1, 'call start vacuuming'\n",
        "if input == \"Alexa, tell Roomba to stop vacuuming\":\n",
        "  numero = 3, 'call stop vacuuming'\n",
        "\n",
        "print(numero)  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'call start vacuuming')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SunUMlbJ1Y9R",
        "outputId": "c627997c-1031-49d1-b349-2ca7a267ecc7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvMT8Go61TLc",
        "outputId": "8666e743-c01e-445f-928a-18e7bcdff1fc"
      },
      "source": [
        "import nltk\n",
        "\n",
        "word_data = \"The best performance can bring in sky high success.\"+'Alexa, ask Roomba to start vacuuming'+'Alexa, ask Braava to start mopping'+'Alexa, tell Roomba to stop vacuuming'\n",
        "'Alexa, tell Braava to stop sweeping'   \n",
        "nltk_tokens = nltk.word_tokenize(word_data)  \t\n",
        "\n",
        "print(list(nltk.bigrams(nltk_tokens)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'best'), ('best', 'performance'), ('performance', 'can'), ('can', 'bring'), ('bring', 'in'), ('in', 'sky'), ('sky', 'high'), ('high', 'success.Alexa'), ('success.Alexa', ','), (',', 'ask'), ('ask', 'Roomba'), ('Roomba', 'to'), ('to', 'start'), ('start', 'vacuumingAlexa'), ('vacuumingAlexa', ','), (',', 'ask'), ('ask', 'Braava'), ('Braava', 'to'), ('to', 'start'), ('start', 'moppingAlexa'), ('moppingAlexa', ','), (',', 'tell'), ('tell', 'Roomba'), ('Roomba', 'to'), ('to', 'stop'), ('stop', 'vacuuming')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpc3XzYV1kfG",
        "outputId": "a05861e7-6116-4096-af22-50c0df6a164b"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def bigram_counts(word_list):\n",
        "\tbgs = nltk.bigrams(word_list)\n",
        "\tfdist = nltk.FreqDist(bgs)\n",
        "\td = Counter()\n",
        "\tfor k, v in fdist.items():\n",
        "\t\td[k] = v\n",
        "\treturn d \n",
        "\n",
        "print(bigram_counts(nltk_tokens))  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({(',', 'ask'): 2, ('Roomba', 'to'): 2, ('to', 'start'): 2, ('The', 'best'): 1, ('best', 'performance'): 1, ('performance', 'can'): 1, ('can', 'bring'): 1, ('bring', 'in'): 1, ('in', 'sky'): 1, ('sky', 'high'): 1, ('high', 'success.Alexa'): 1, ('success.Alexa', ','): 1, ('ask', 'Roomba'): 1, ('start', 'vacuumingAlexa'): 1, ('vacuumingAlexa', ','): 1, ('ask', 'Braava'): 1, ('Braava', 'to'): 1, ('start', 'moppingAlexa'): 1, ('moppingAlexa', ','): 1, (',', 'tell'): 1, ('tell', 'Roomba'): 1, ('to', 'stop'): 1, ('stop', 'vacuuming'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oqHfjCD2rrc",
        "outputId": "63074850-8d43-4283-d053-dbe729365116"
      },
      "source": [
        "def trigram_counts(word_list):\n",
        "\ttgs = nltk.trigrams(word_list)\n",
        "\tfdist = nltk.FreqDist(tgs)\n",
        "\td = Counter()\n",
        "\tfor k, v in fdist.items():\n",
        "\t\td[k] = v\n",
        "\treturn d\n",
        "\n",
        "print(trigram_counts(nltk_tokens))    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('The', 'best', 'performance'): 1, ('best', 'performance', 'can'): 1, ('performance', 'can', 'bring'): 1, ('can', 'bring', 'in'): 1, ('bring', 'in', 'sky'): 1, ('in', 'sky', 'high'): 1, ('sky', 'high', 'success.Alexa'): 1, ('high', 'success.Alexa', ','): 1, ('success.Alexa', ',', 'ask'): 1, (',', 'ask', 'Roomba'): 1, ('ask', 'Roomba', 'to'): 1, ('Roomba', 'to', 'start'): 1, ('to', 'start', 'vacuumingAlexa'): 1, ('start', 'vacuumingAlexa', ','): 1, ('vacuumingAlexa', ',', 'ask'): 1, (',', 'ask', 'Braava'): 1, ('ask', 'Braava', 'to'): 1, ('Braava', 'to', 'start'): 1, ('to', 'start', 'moppingAlexa'): 1, ('start', 'moppingAlexa', ','): 1, ('moppingAlexa', ',', 'tell'): 1, (',', 'tell', 'Roomba'): 1, ('tell', 'Roomba', 'to'): 1, ('Roomba', 'to', 'stop'): 1, ('to', 'stop', 'vacuuming'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9grKIKXAYSk"
      },
      "source": [
        "«Alexa, démarre la machine à café Home Connect» ou «Alexa, dis à la machine à café Home Connect de démarrer». \n",
        "Alexa entame le dialogue immédiatement, et vous guide tout au long des étapes.\n",
        "\n",
        "Si vous maîtrisez déjà la compétence, essayez de faire une demande plus complexe; par exemple: \n",
        "«Alexa, dis à la machine à café Home Connect de faire un cappuccino.». \n",
        "Ce raccourci vous permet de sélectionner votre café préféré rapidement et directement en une seule phrase. \n",
        "Pour cela, la machine à café utilise les derniers réglages utilisés pour la contenance et la force.\n",
        "\n",
        "Si vous avez une préférence personnelle pour le café, donnez directement toutes les indications: \n",
        "«Alexa, dis à la machine à café Home Connect de faire un grand cappuccino très serré.». \n",
        "\n",
        "Si Alexa ne comprends pas correctement tous les mots, l'Assistant vient automatiquement à votre rescousse.\n",
        "\n",
        "Il se peut également que la machine à café soit en veille au moment de votre demande. Dans ce cas, la machine à café démarre automatiquement et lance le cycle de rinçage. \n",
        "Patientez quelques minutes jusqu'à la fin du cycle et recommencez.\n",
        "\n",
        "Voici quelques conseils: si vous ne savez pas exactement quoi dire pendant un dialogue, attendez quelques secondes, \n",
        "Alexa fera automatiquement quelques suggestions. Vous pouvez mettre fin au dialogue quand vous le souhaitez en disant «Interrompre» ou «Arrêter»."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cRY_jqx-c5f"
      },
      "source": [
        "Voir Intro-to-NLP.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wntbq4HL7xjP"
      },
      "source": [
        "{'ROOMBA': {'START': ['Alexa, ask Roomba to start vacuuming',\n",
        "   'Alexa, ask Braava to start mopping'],\n",
        "  'STOP': ['Alexa, tell Roomba to stop vacuuming',\n",
        "   'Alexa, tell Braava to stop sweeping']}}\n",
        "\n",
        "'Alexa, ask Roomba to start vacuuming',\n",
        "'Alexa, ask Braava to start mopping',\n",
        "'Alexa, tell Roomba to stop vacuuming',\n",
        "'Alexa, tell Braava to stop sweeping'   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SryVF3wX8fbM",
        "outputId": "de7b2124-af60-4232-8914-7f074a01d732"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # We will use it later\n",
        "\n",
        "sentences = [\n",
        "'Alexa, ask Roomba to start vacuuming',\n",
        "'Alexa, ask Braava to start mopping',\n",
        "'Alexa, tell Roomba to stop vacuuming',\n",
        "'Alexa, tell Braava to stop sweeping',\n",
        "'Ok Google, quelles sont les actualités ?',\n",
        "'Ok Google, quelles sont les actualités économiques ?',\n",
        "'Ok Google, quelles sont les actualités technologie ?'   \n",
        "]\n",
        "\n",
        "# Create object of Tokenizer and tokenize sentences\n",
        "tokenizer = Tokenizer(num_words = 100)  # max distinct words first 100 words\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index  # returns dictionary\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alexa': 1, 'to': 2, 'ok': 3, 'google': 4, 'quelles': 5, 'sont': 6, 'les': 7, 'actualités': 8, 'ask': 9, 'roomba': 10, 'start': 11, 'vacuuming': 12, 'braava': 13, 'tell': 14, 'stop': 15, 'mopping': 16, 'sweeping': 17, 'économiques': 18, 'technologie': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsMMnr-V9DBv",
        "outputId": "c3b425a4-a375-49e3-8be0-594bbf2379f7"
      },
      "source": [
        "import pprint\n",
        "# at Tokenizer instance creation add another keyword argument\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOv>')  # OOV means Out of vocabulary\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index=tokenizer.word_index\n",
        "sequences=tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "pprint.pprint(word_index)\n",
        "print(\"\\nTest Sequence = \")\n",
        "pprint.pprint(sequences)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<OOv>': 1,\n",
            " 'actualités': 9,\n",
            " 'alexa': 2,\n",
            " 'ask': 10,\n",
            " 'braava': 14,\n",
            " 'google': 5,\n",
            " 'les': 8,\n",
            " 'mopping': 17,\n",
            " 'ok': 4,\n",
            " 'quelles': 6,\n",
            " 'roomba': 11,\n",
            " 'sont': 7,\n",
            " 'start': 12,\n",
            " 'stop': 16,\n",
            " 'sweeping': 18,\n",
            " 'technologie': 20,\n",
            " 'tell': 15,\n",
            " 'to': 3,\n",
            " 'vacuuming': 13,\n",
            " 'économiques': 19}\n",
            "\n",
            "Test Sequence = \n",
            "[[2, 10, 11, 3, 12, 13],\n",
            " [2, 10, 14, 3, 12, 17],\n",
            " [2, 15, 11, 3, 16, 13],\n",
            " [2, 15, 14, 3, 16, 18],\n",
            " [4, 5, 6, 7, 8, 9],\n",
            " [4, 5, 6, 7, 8, 9, 19],\n",
            " [4, 5, 6, 7, 8, 9, 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH6dPSMV9iKK",
        "outputId": "22c5c9b9-f204-48ce-e3d7-d7bd37c2e2c7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_sequences = pad_sequences(sequences, padding='pre',truncating='post',maxlen=15)\n",
        "print(padded_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  2 10 11  3 12 13]\n",
            " [ 0  0  0  0  0  0  0  0  0  2 10 14  3 12 17]\n",
            " [ 0  0  0  0  0  0  0  0  0  2 15 11  3 16 13]\n",
            " [ 0  0  0  0  0  0  0  0  0  2 15 14  3 16 18]\n",
            " [ 0  0  0  0  0  0  0  0  0  4  5  6  7  8  9]\n",
            " [ 0  0  0  0  0  0  0  0  4  5  6  7  8  9 19]\n",
            " [ 0  0  0  0  0  0  0  0  4  5  6  7  8  9 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYkIYZn3FuYP",
        "outputId": "bf3c8ecd-cea4-4aa3-abc7-2a64b8defb94"
      },
      "source": [
        "# inverse mapping using zip and dict functions \n",
        "inv_dict = dict(zip(word_index.values(), word_index.keys())) \n",
        "\n",
        "# print final dictionary \n",
        "print(\"inverse mapped dictionary : \")\n",
        "pprint.pprint(str(inv_dict)) \n",
        "print(inv_dict[2]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inverse mapped dictionary : \n",
            "(\"{1: '<OOv>', 2: 'alexa', 3: 'to', 4: 'ok', 5: 'google', 6: 'quelles', 7: \"\n",
            " \"'sont', 8: 'les', 9: 'actualités', 10: 'ask', 11: 'roomba', 12: 'start', 13: \"\n",
            " \"'vacuuming', 14: 'braava', 15: 'tell', 16: 'stop', 17: 'mopping', 18: \"\n",
            " \"'sweeping', 19: 'économiques', 20: 'technologie'}\")\n",
            "alexa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVG5o8TF7vgE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc25pF3P7NCp"
      },
      "source": [
        "pip install -q tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJiQug-a6b_t"
      },
      "source": [
        "pip install -q tensorflow-text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am01101h6pev"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovLfXc6c6vk_",
        "outputId": "6a5eef82-f180-4d92-d8b6-0c2e68fe0df2"
      },
      "source": [
        "docs = tf.constant([u'Everything not saved will be lost.'.encode('UTF-16-BE'), u'Sad☹'.encode('UTF-16-BE')])\n",
        "utf8_docs = tf.strings.unicode_transcode(docs, input_encoding='UTF-16-BE', output_encoding='UTF-8')\n",
        "utf8_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
              "array([b'Everything not saved will be lost.', b'Sad\\xe2\\x98\\xb9'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceff-jxT6-nY",
        "outputId": "ea726e36-cd54-4805-91a7-88eccdbf308a"
      },
      "source": [
        "tokenizer = text.WhitespaceTokenizer()\n",
        "tokens = tokenizer.tokenize(['everything not saved will be lost.', u'Sad☹'.encode('UTF-8')])\n",
        "print(tokens.to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[b'everything', b'not', b'saved', b'will', b'be', b'lost.'], [b'Sad\\xe2\\x98\\xb9']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}